---
title: "Bilan d'une année d'expérience avec Mastodon"
subtitle: "activité du compte Mastodon du service ARDEL"
author: "Damien Belvèze" 
output: 
  html_document:
      toc: true
      toc-depth: 2
#      toc_float:
#        collapsed: true
#        smooth_scroll: false
      theme: cerulean
css: style.css
bibliography: biblio.bib
csl: nature.csl
date: "2025-01-15"
---


```{r 1_authentification avec rtoot, eval=FALSE, include=FALSE}
library(rtoot)
auth_setup()
# Si ces deux lignes de code ne sont pas exécutées en amont de la compilation (knit) de ce document, une erreur 503 est affichée. 
# Pour exécuter ce chunck, il faut avoir son navigateur et avoir ouvert le compte SO_UnivRennes et donc pour cela disposer de l'identifiant et du mot de passe du compte
```

```{r extraction de données avec rtoot, include=FALSE}
library(readr)
options(readr.show_col_types = FALSE) #voir ici https://github.com/tidyverse/readr/issues/1250
library(rtoot)
library(tidyverse)
library(dplyr)
library(tufte)

last_run_time <- Sys.time()
id <- "112370075539544475"
followers <- get_account_followers(id, limit = 300L)
following <- get_account_following(id, limit = 300L)
lists <- get_account_lists(id, token = NULL, parse = TRUE)
print(lists)
#relationships <- get_account_relationships(id, limit = 300L)
dataframe <- get_account_statuses(id, limit = 400L)
toots <- get_account_statuses(id, exclude_reblogs = TRUE, limit = 400L)
sent <- as.integer(length(dataframe$id))
toots <- as.integer(length(toots$id))
boosts <- (sent - toots)
reblogs <- sum(dataframe$reblogs_count)
favourites <- sum(dataframe$favourites_count)
replies <- sum(dataframe$replies_count)
reply_to <-dataframe$in_reply_to_id

followers_number <- length(followers$id)
following_number <- length(following$id)
#relationships_number <- length(relationships$id)
status_number <- length(dataframe$id)
#print(dataframe)

write_csv(dataframe, "SO_univrennes_toots.csv")
write_csv(followers, "followers.csv")
#write_csv(relationships, "relationships.csv")
#print(followers)
#print(followers_number)
```


```{r replies to users, include=FALSE}

reply_to <- dataframe$in_reply_to_account_id %>%
    .[!is.na(.) & . != "NA"]   #
count_reply_to <- length(reply_to)

```

# 1. Pourquoi nous avons choisi Mastodon

## 1.1 Périmètre du compte

ARDEL, auquel est rattaché le [compte SO_UnivRennes](https://mastodon.social/@SO_UnivRennes) est le service d'**Appui à la Recherche et à la Documentation En Ligne** (ARDEL) du Service Commun de Documentation (SCD) de l'Université de Rennes. L'activité d'ARDEL ne se limite pas à la Science Ouverte, mais elle y prend néanmoins une part importante dans les fiches de postes de 4 agents sur les 6 que compte le service, exclusive chez 2 d'entre eux. 

Le compte SO_UnivRennes ne parle d'ailleurs pas uniquement de Science Ouverte mais a vocation à partager des informations sur l'ensemble des activités des membres du groupe ARDEL, dans lesquelles on trouve la documentation en ligne gérée par le SCD, les formations doctorales et la gestion des thèses en tant que production scientifique de notre Université. Pour le reste, en effet, la Science Ouverte recouvre la sensibilisation et l'accompagnement des chercheurs et chercheuses (y compris les doctorant.e.s) à la conservation, à la diffusion et au partage des publications dans et depuis HAL, des données dans et depuis Recherche Data Gouv ou d'autres entrepôts de confiance et du code source dans Software Heritage et depuis HAL.

Inversement, au sein de l'Université de Rennes, la Science Ouverte est présente bien au delà de la cellule ARDEL et infuse les politiques de l'Université. Elle dispose d'un chargé de mission qui est aussi chargé de la documentation. 

Ces éléments qui ne figurent pas encore sur la "bio" de notre compte a du être précisée dans un message de réponse à une utilisatrice, enseignante-chercheuse à l'Université de Rennes, qui sollicitait notre avis sur une contradiction apparente entre la théorie et la pratique de la Science Ouverte par notre Université.
Le Service Commun de la Documentation a vocation à contribuer par son expertise à la construction de la politique Science Ouverte de l'Université, mais celle-ci est en dernière instance définie par le conseil scientifique. Le compte SO_UnivRennes communique sur les éléments de cette politique et aide les chercheurs et les chercheuses inscrit.e.s sur Mastodon à la mettre en oeuvre au quotidien.  

## 1.2 Mastodon : un choix conforme à la Science Ouverte

Un service comme ARDEL pourrait se satisfaire de l'usage de son site web pour communiquer et de l'utilisation de flux RSS pour suivre les principales évolutions sur la Science Ouverte et la documentation électronique tant les sources d'information fiables et inspirantes sont nombreuses :  sites de revues spécialisées, sites d'institutions de recherche, de chercheurs et chercheuses, et de personnes appartenant au monde de la documentation et des bibliothèques. Devant le discrédit dans lequel X plonge une partie des autres réseaux sociaux, beaucoup d'individus actifs dans le monde du logiciel ou de la recherche quittent ces plateformes dites "sociales" pour passer plus de temps à lire les billets des sites qu'elles apprécient et à écrire et publier des billets sur leur propre site[¹]. 

### 1.2.1 Les flux RSS et les sites web ne suffisent pas

En tant que service, nous considérons que la fréquentation d'un réseau social ajoute un élément important à une veille qui ne reposerait que sur des flux. Cet apport réside dans la confrontation de perpectives différentes sur un même objet, de points de vue parfois opposés sur telle ou telle pratique. Etre témoin de ces conversations nous permet de prendre en considération davantage de situations et d'affiner nos réponses en fonction de celle dans laquelle se trouvent nos interlocuteurs et interlocutrices. Prendre part à ces conversations permet *a fortiori* d'éprouver des arguments au contact de collègues ou de personnels de recherche qui ont une autre expérience de terrain que la nôtre. Bien sûr, les blogs de 2010 donnaient l'occasion d'enclencher ce genre de conversation, mais avec l'essor des réseaux sociaux, force est de constater que les tenanciers de blogs ont perdu l'habitude de répondre aux commentaires de leurs posts. 

Nous pensons toutefois que ces conversations ne peuvent être enrichissantes que dans la mesure où elles surviennent dans un climat propice. Ce climat est à la fois une question de comportement (attention, politesse, netétiquette), de réglages (possibilité de bloquer, de signaler des comptes malveillants) et de transparence. Il ne sert à rien de continuer de briser des lances avec les afficionados d'extrême droite qui peuplent X, dans la mesure où le propriétaire du réseau peut à loisir modérer notre écho et amplifier celui de nos adversaires. Quand le jeu est truqué, il faut refuser de jouer. 

Par transparence, nous entendons donc d'abord **transparence de l'algorithme de distribution des messages** : 
Nous devons nous assurer que tout ce qui est posté par un.e utilisatreur.ice du réseau nous parvient sans filtre, à la manière d'un flux RSS qui reproduit fidèlement tout ce qui est posté par la personne qu'on suit. Ce n'était plus le cas sur Twitter déjà bien avant qu'Elon Musk ne le rachète. Mastodon n'est qu'un logiciel dont le code source est accessible. Le réseau social Fedivers dépend d'un protocole (ActivityPub) qui préexistait au logiciel Mastodon et son code est également en accès libre. 

### 1.2.2 Communiquer, c'est faire du Commun

Nous souhaitons par ailleurs investir du temps dans un Commun, car nous considérons que communiquer, ce n'est pas seulement échanger des messages, mais aussi contribuer au milieu (medium) qui permettra à ces échanges d'avoir lieu. Communiquer, comme le rappelle Arthur Perret, c'est aussi bâtir du Commun (@perretFaireCommun2023a), a contrario des réseaux sociaux centralisés qui privatisent (de la donnée personnelle) et privilégient des points de vue au détriment d'autres par des algorithmes opaques et déloyaux. 

Créer du commun, c'est précisément interroger le medium qu'on utilise, ses règles, ses principes de modération, son articulation avec les médias voisins quand elle est techniquement possible. Par exemple, les instances de Mastodon peuvent techniquement communiquer avec celles de Threads (Meta), mais ne le souhaitent pas pour éviter que le Fédivers ne soit victime de la part de Meta d'une manoeuvre de style **embrace, extend and extinguish**. 

Avec Mastodon, il n'y a pas de propriétaire qui décide de cette interopérabilité pour tout le monde. L'administrateurice d'une instance peut rendre le choix de l'ouverture possible à ses utilisateurices (sans pouvoir la rendre obligatoire) ou bien proposer que la connexion ne soit pas possible pour la raison stratégique évoquée. Ces débats ont lieu au sein des instances avec les utilisateurices. Il n'y pas de procédure de vote à notre connaissance, mais les personnes mécontentes de la décision prise peuvent sans perdre l'accès à leur communauté de followers quitter cette instance pour une autre qui correspond mieux à leurs options d'ouverture (ou de fermeture). Cet exemple, montre qu'il est possible de bâtir des Communs avec Mastodon, alors qu'un gouvernement centralisé dans les mains d'un propriétaire qui dispose de toutes les règles et décide de tous les paramétrages obère d'emblée cette construction.  

### 1.2.3 La décentralisation, l'atout maître de Mastodon

Répétons-le, Mastodon n'est qu'un logiciel et pas un réseau social qui permet d'accéder à un réseau structuré par un protocole d'échange, ActivityPub, l'un et l'autre sont libres. 
Pour les utilisateurices de X qui ne supportent pas la dégradation de plus en plus nette de leur expérience sur ce réseau et la toxicité accrue du réseau du fait d'une absence de modération, la difficulté d'intégrer Mastodon est en réalité ce qui constitue la richesse de cet écosystème : Mastodon comporte un grand nombre d'instances de tailles et de politiques différentes, et il faut en choisir une : **Où atterrir ?**

Nous nous sommes évidemment posé la question et nous avons comparé les diverses instances qui accueillent les acteurs de la Science ainsi que celles qui travaillent dans le périmètre de l'Etat. Nous avons d'abord contacté l'instance gérée par la Direction du Numérique (Dinum) qui nous paraissait la plus appropriée, mais faute de réponse de l'administrateur à ce moment-là, nous avons opté pour la solution généraliste *mastodon.social*, celle qui compte le plus grand nombre de comptes hébergés à ce jour. 

Depuis, lors nous avons échangé avec les administrateurs de l'instance *[social.numerique.gouv.fr](https://social.numerique.gouv.fr/explore)* de la [Direction Interministérielle du Numérique](https://www.numerique.gouv.fr/dinum/) qui nous incitent à choisir leur serveur dédié aux services de l'Etat. Dans le même temps, nous sommes en contact avec un agent du [Service interuniversitaire en charge de la mutualisation numérique en île-de-France (UNIF)](https://unif.fr/qui-sommes-nous/). 
L'UNIF a ouvert fin janvier une [instance destinée au monde universitaire qui intègre la Fédération d'Identité](https://universites.social/about). L'accès se fait au moyen d'identifitants universitaires. Ce mode d'accès rendrait un compte partagé comme le nôtre plus résistant aux attaques d'usurpation, dans la mesure où sur une instance dépourvue de ce type de gestion de droits, il n'est pas possible de mettre en place un système de double authentification impliquant une application idoine sur un smartphone commun. 

Nous avons mentionné la dégradation de l'expérience usager sur une plateforme comme X/Twitter. 
Cory Doctorow qui a étudié ce phénomène commun à nombre de plateformes ultra-dominantes sur le marché à forgé à ce sujet le concept d'**emmerdification** (enshittification). 
Ce phénomène décrit la manière dont les propriétaires d'une plateforme accordent une telle importance au retour sur investissement pour satisfaire la demande actionnariale (ou politique en ce qui concerne Meta et Twitter) que non seulement les demandes des usagers ne sont plus prises en compte, mais de plus celles des partenaires commerciaux (publicitaires) sont également négligées. 

Les usagers, pour ne parler que d'eux, acceptent pendant quelque temps de subir cette dégradation afin de garder aussi longtemps que possible leur communauté et leurs contacts. Car e,n l'espère, partir, signifie perdre le bénéfice de plusieurs années de constructions d'une communauté. C'est pourtant ce à quoi ils/elles douivent se résoudre quand la toxicité sur ces plateformes confinent au harcèlement. 

Aussi pour Cory Doctorow, **ce n'est pas tant le fait que des capitaux privés soutiennent une infrastructure qui condamnent celle-ci à l'emmerdification, mais le fait qu'elle rend ses usagers captifs de cette infrastructure** (@doctorowEnshittificationIsntCaused2024). 

A contrario, comme on l'a vu plus haut, le Fédivers conserve à ses utilisateurices toute latitude pour quitter une instance dont l'administration ou la politique générale leur déplairait pour une autre plus proche de leurs options, et cela sans aucune perte de leur expérience passée. Comptes suivis, followers, listes, messages envoyés accompagnent le ou la migrante vers sa nouvelle maison.

Cory Doctorow observe par ailleurs que si cette liberté est inscrite dans le code du protocole de Bluesky (AT), elle n'est toujours pas enracinée dans une réelle décentralisation et rien ne garantit qu'elle ne le soit un jour (@doctorowBlueskyEnshittification2025). De son point de vue, cette incertitude devrait nous conduire à opter pour une solution qui tient d'emblée ses engagements, ce que fait Mastodon, **enraciné dans le Fédivers (Fediverse), un réseau décentralisé dans sa conception même et depuis ses origines**.

Sur la récente capitalisation de Bluesky, Joan Westenberg a un point de vue divergent de celui de Doctorow. Pointant du doigt l'arrivée massive sur Bluesky d'utilisateurices fuyant X/Twitter, elle pose la question suivante : **est-ce qu'une plateforme financée à coups de le grand capital (elle était évaluée à 700 millions de dollars en décembre 2024) peut réellement servir de refuge à des gens qui fuient l'arbitraire et les obessions des Tech Bros de Meta et X ?** 

Le financement de Bluesky condamne ses administrateurices à la pression d'un retour sur investissement rapide, qui se traduit dans un premier temps par l'ouverture à la publicité (@rothThreadsOfficallyGetting2025) et devrait ensuite prendre les apparences de ce que nous avons déjà observé sur Twitter (@westenbergWhatBlueskys700m2025). 

Ajoutons à cela que des ponts techniques (*bridges*) existent entre les protocoles de Bluesky et de Mastodon, nous en reparlerons. Ces ponts permettent aux utilisateurices de chaque plateforme de suivre celles de l'autre, ces trois raisons (décentralisation effective, organisation à but non lucratif, interopérabilité avec le protocole AT) fait qu'ARDEL n'envisage pas de créer un compte sur Bluesky et de crossposter. 

## 1.3 Qu'en est-il des autres alternatives : LinkedIn et Threads

### 1.3.1 Threads

Threads partage avec Mastodon un même protocole, mais les règles y sont très différentes. l'algorithme du réseau expose du contenu provenant de comptes qu'on ne suit pas et il est impossible pour l'usager qu'il en soit autrement, on ne peut donc parler d'un algorithme loyal ni transparent. La modération y sera sous peu soumise aux nouvelles régles de "modération" imposées aux équipes de Meta : la modération des contenus ne sera plus confiée à des officines extérieures (rédaction de journaux) mais aux usagers eux-mêmes qui décideront collaborativement de l'acceptabilité d'un post ; un Commun ? cette mesure déjà appliquée à d'autres réseaux de la *Broligarchie*[²] n'aura pas pour effet de garantir la liberté d'expression contre les sachants, mais de déplacer la fenêtre d'Overton encore plus vers la droite (et de la fermer à gauche) selon les intérêts du moment du PDG de Meta.
Bien sûr il y a aussi des instances sur Mastodon tenues par des libertariens et des climaosceptiques, mais nul n'est obligé de s'y inscrire. Il y a tant d'autres instances possibles où atterrir. Piaille par exemple régule les échanges et bannit les contenus ouvertement climatosceptiques en tant que "désinformation" conformément à sa charte [³]. 

Threads, comme Facebook ne sont pas moins orthogonaux que X avec les idéaux d'universalisme et de recherche de la vérité scientifique des universités. Le RGPD commanderait aussi de ne jamais laisser de pouce levé sur une page de nos universités, ce qui revient à laisser constituer des "shadow profiles" à partir des données de navigation de nos usagers, mais on sait ce qu'il en est dans la réalité. Pour les bibliothèques, l'impératif d'aller "où sont nos usagers" semble prévaloir dans les choix opérés à la faveur du #HelloquitteX. Pour autant, cet impératif n'a que rarement incité ces établissements ou les universités à ouvrir un compte sur le réseau Tiktok, un lieu très fréquentés les usagers et usagères des 18-25 ans  l'emporte nettement sur notre recheche de cohérence entre nos valeurs et les outils qu'on utilise, ainsi bien sûr que cette pédagogie du numérique que nous devons à nos étudiants et qui devrait nous inciter à leur présenter de nouvelles manières plus éthiques de communiquer en ligne.

### 1.3.2 LinkedIn

LinkedIn est un réseau largement utilisé par des chercheurs et les chercheuses pour entretenir un réseau professionnel afin d'y trouver une visibilité pour de futurs employeurs et des opportunités de partenariats ou d'embauches. Ces enjeux n'ont que peu de liens avec l'objet qui occupe ARDEL, la Science Ouverte. 
LinkedIn est également un réseau qui illustre le concept de capitalisme de plateforme tel que défini par Shoshana Zuboff. Les données personnelles qui y sont échangées (et vraisemblablement certaines autres qui sont directement prélevées auprès de ou de la nouvelle inscrite) servent à accroître la valeur monétaire du réseau.
La position de LinkedIn vis à vis des contenus générés par des outils d'intelligence artificielle nous semble encore plus problématique. LinkedIn a annoncé récemment que loin de réguler le contenu généré par des IA, (les bots doivent être signalés comme tels sur Mastodon), le réseau facilitait le recours à ces outils en son sein (au titre d'"assistants de rédaction"). Des études récentes estiment à 54% le contenu en anglais présent sur la plateforme qui a été généré avec l'aide d'une IA, et à 23% le contenu entièrement généré par un outil d'IA (@knibbsYesThatVirala). 
La Science Ouverte n'a rien à faire ni rien à gagner dans un univers aussi synthétique. 


## 1.4 Ouverture d'un compte sur Mastodon

Le contexte du rachat de Twitter par Elon Musk et les mises en veille successives des comptes X des Universités de Rennes 2 puis de Rennes ont amené les services de communication de ces deux universités à revoir leur politique relative aux médias sociaux. Nous avons mené notre propre réflexion de notre côté sous la supervision de la direction de la bibliothèque et du service de communication de l'Université de Rennes. Nous avons ouvert le compte SO_UnivRennes le 2 mai 2024 non sans avoir au préalable sélectionné une liste de comptes à suivre en rapport avec nos activités. L'usage de Mastodon par l'un d'entre nous a certes facilité ce travail d'argumentation et d'identification des instances d'hébergement et de comptes à suivre. Le message le plus populaire (d'après le site [Mastodon Academy](https://mastodon.academy/by/@SO_UnivRennes@mastodon.social)) que nous avons envoyé sur Mastodon comportait un lien vers le [guide de démarrage sur Mastodon](https://zenodo.org/records/14170125) republié en novembre 2024 par les collectifs The Carpentries et rOpenSci. Nous espérons comme les auteurs de ce guide que cette ressource a déjà aidé et aidera encore les institutions de recherche à mieux comprendre le Fédivers et à s'y domicilier pour communiquer avec leurs communautés. 
Nous avons aussi bénéficié des informations envoyées sur la liste de diffusion ["Transition Réseaux Sociaux"](https://groupes.renater.fr/sympa/info/transition_reseaux_sociaux) ouverte par la BULAC qui cherchait à la même époque à quitter X pour des réseaux plus éthiques. La BULAC est aujourd'hui présente sur Mastodon et Bluesky. Nous recommandons aux bibliothèques qui voudraient se lancer dans l'un ou l'autre de s'incrire à cette liste. 
Afin de pouvoir suivre les utilisateurices de Bluesky qui ont activé leur pont vers Mastodon, nous avons activé le nôtre en direction de Bluesky. Nous en avons déjà parlé, nous y reviendrons. 
Nous avons mené une recherche sur les mots-clé en rapport avec notre université, sans détecter beaucoup de comptes provenant de notre communauté. Les "migrations" de comptes universitaires de X vers les réseaux alternatifs n'avaient pas encore trouvé leur pic (le 20 janvier avec le mot d'ordre #HelloquitteX). 
Nous avons entamé en direction du Service Communication de l'Université une demande en vue d'introduire notre handle Mastodon dans le code source d'une page de notre site. Ce handle doit figurer dans l'entête ce qui nécessite des droits complets d'administration sur ce site. La vérification des comptes n'existe pas sur Mastodon, mais on peut en revanche certifier que tel compte appartient bien à telle institution qui a la main sur tel ou tel site, ce qui permet au compte en question de bénéficier de la confiance accordée au site (@godefroidCommentCertifierCompte2024a).  
Cette fonctionnalité permettrait en outre d'afficher notre profil en lien avec n'importe lequel de nos posts quelque soit l'utilisateurice qui le boosterait (@rochkoHighlightingJournalismMastodon2024). 



# 2. Analyse de notre activité sur Mastodon

L'activité sur Mastodon peut être mesurée et interrogée au moyens d'API. Des collectifs ont commencé à distribuer des librairies pour R et pour Python qui permettent à des chercheurs et chercheuses d'extraire des contenus de la plateforme (listes d'utilisateurs, listes de statuts comportant un mot clé donné sur une instance ou plusieurs). Mais ces librairies sont également utiles pour des administrateurices d'instances afin de connaître le contenu qui transite par leur serveur en interaction avec les autres serveurs fédérés ou aux détenteurs de comptes individuels ou collectifs comme le nôtre. 
Nous avons décidé de mener cette analyse avec un package réalisé pour R, car le mode d'authentification promu par ce package nous a semblé plus simple que celui mis en oeuvre par la [librairie Python](https://mastodonpy.readthedocs.io/en/stable/) conçue pour Mastodon. 

## 2.1 Le package Rtoot

David Schoch et Chung-Hong Chan sont à l'origine du package Rtoot conçu pour R qu'ils ont présenté dans les colonnes de la revue *Mobile Media & Communication* (@schochSoftwarePresentationRtoot2023a). Ce paquet est téléchargeable [depuis le répertoire du CRAN](https://cran.r-project.org/web/packages/rtoot/index.html). Comme une partie des requêtes possibles par API nécessite une authentification, ce package gère cette authentification au moyen d'un token qui peut être obtenu quand on est connecté au compte à analyser. 

Les commandes qui déclenchent ce processus d'authentification sont indiquées ci-dessous : 

```{r eval=FALSE}
library(rtoot)
auth_setup()
```

Dans la console, l'application demande le nom de l'instance qui héberge le compte. Il faut fournir le nom de cette instance entre guillemets ( "mastodon.social" )
Puis choisir "User" si on veut obtenir les chiffres relatifs à un compte d'utilisateur. 
Si le navigateur est ouvert et que le compte est ouvert sur l'un de ses onglets, en quelques secondes une fenêtre apparaît demandant l'autorisation d'utiliser Rtoot avec le compte en question. Une fois autorisée, cette transaction aboutit à l'affichage d'un jeton (token) sous la forme d'une chaîne de caractères. Du côté de R, un popup demande ce jeton. Lorsque il lui est fourni, il est possible d'exécuter les commandes de Rtoot qui permettent d'obtenir des informations sur l'activité de ce compte. 

Le code source de cette publication fournit les requêtes utilisées pour recueillir les données qui ont permis d'extraire les chiffres qui sont présentés dans ce document. 
Pour utiliser ce code avec un autre compte que celui de SO_UnivRennes, il faut utiliser rtoot pour récupérer l'identifiant numérique du compte (celui de SO_UnivRennes est "112370075539544475") et remplacer notre identifiant par le votre dans la ligne suivante : 

```{r eval=FALSE}
id <- "votre numéro"
```

Pour trouver cet identifiant, on utilise la fonction search_account du package rtoot : 

```{r eval=FALSE}
id <- search_accounts("SO_UnivRennes")
print(id)
# donne 112370075539544475
```

Dans le présent document, les chiffres en bleu et en gras comportent les chiffres obtenus lorsqu'on a exécuté pour la dernière fois la commande auth_setup (=lorsqu'on a compilé le présent document pour la dernière fois), c'est à dire à cette date : <div class="blue">`r last_run_time`</div>.


## 2.2 Présence de Mastodon dans l'enseignement supérieur français et européen d'après les données de Wikidata

La plupart des bibliothèques qui ont quitté X se sont demandé où allaient leurs usagers. Question très légitime, même si l'on devrait garder une distance critique vis à vis de la réponse. Doit-on suivre la masse de nos anciens followers ou bien doit-on suivre plutôt les opportunités qui s'ouvrent à nous, dans un contexte où la plus grande partie des réseaux sociaux, en fait tous les réseaux sociaux centralisés, suivent les évolutions et les crises du capitalisme.
Pour notre part, nous avons cherché à savoir quels mouvements étaient à l'oeuvre au sein des institutions de recherche d'une part et des bibliothèques d'autre part, une bibliothèque universitaire partageant des traits communs à l'un et l'autre monde. Nous avons souhaité aussi observer ces dynamiques au niveau international et pas seulement au niveau français, afin d'être en mesure d'évaluer les ressorts nationaux qui peuvent aider ou entraver l'adoption de réseaux sociaux vraiment alternatifs comme Mastodon.

### 2.2.1 Comptes gérés par des universités et instituts de recherche

Pour obtenir des informations sur l'adoption des réseaux sociaux par les institutions de recherche et les bibliothèques, nous nous sommes fondés sur les données de Wikidata. Une source sans doute incomplète mais qui permet néanmoins d'obtenir des résultats qui nous paraissent significatifs et qui sont reproduits ci-dessous. 

Une requête Wikidata permet d'obtenir la liste des institutions de recherche qui **d'après les données de Wikidata** se sont dotées d'un compte Mastodon, Bluesky, etc.
Le logiciel R au moyen du [package wikidataR](https://cran.r-project.org/web/packages/WikidataR/WikidataR.pdf) permet d'initier cette requête dans l'environnement d'édition de R, ce qui est la méthode que nous avons suivie.
La fiabilité de ces chiffres obtenus dépend du travail d'enrichissement que la communauté opère sur Wikidata à partir des données présentes sur le web. 
Techniquement, il est possible de remplir un tableau avec une liste d'institutions dans la première colonne, leur identifiant Wikidata dans la seconde, et dans la troisième, la liste de leurs *handles* (identifiants) sur les différents réseaux sociaux, pour enrichir leurs profils sur Wikidata. Le package WikidataR prend également en charge cette fonction de "quickstatement" groupé. Mais ces tableaux sont fastidieux à faire. Nous ne connaissons pas de système pour recueillir automatiquement et automatiser l'alignement de ces identifiants. Nous nous basons donc sur une somme importante de petits enrichissements qui ont été réalisés sur un grand nombre d'internautes qui savent éditer Wikidata et ont à coeur d'y compléter le profil de leur institution. 


Le résultat de cette requête est lisible dans le [fichier Wikidata_all.csv](wikidata_all.csv) 

Quels types de comptes "alternatifs" à X/Twitter, Facebook ou Instagram (Meta) les institutions de recherche ouvrent-elles lorsqu'elles quittent X ?

Nous faisons entrer ici dans la catégorie *réseaux alternatifs* des réseaux que nous en considérons pas comme de réelles alternatives (puisque pour nous seuls les services actuellement présents sur le Fédivers méritent vraiment ce nom), mais qui sont souvent considérés comme tels dans les études portant sur l'émigration en cours des comptes de chercheurs et chercheuses hors de Twitter.
La littérature scientifique sur le sujet mentionne essentiellement Mastodon, Bluesky, Threads et LinkedIn comme réseaux de destination et c'est une sélection que nous reprenons à notre compte. 

```{r requête Wikidata tous pays, echo=FALSE}
library(WikidataR)
library(dplyr)
library(ggplot2)
wikidata_df <- query_wikidata('SELECT DISTINCT ?institution ?institutionLabel ?Mastodon ?Bluesky ?LinkedIn ?Facebook ?Threads ?Instagram ?countryLabel WHERE {
  ?institution wdt:P31/wdt:P279* wd:Q31855;
    wdt:P17 ?country .

# Institutions de recherche : wd:Q31855
# bibliothèques : wd:Q7075

  {
    ?institution wdt:P4033 ?Mastodon
  } UNION {
    ?institution wdt:P12361 ?Bluesky
  } UNION {
    ?institution wdt:P4264 ?LinkedIn
  }  UNION {
    ?institution wdt:P11892 ?Threads
  } 
 #   UNION {
 #   ?institution wdt:P2003 ?Instagram
 # } UNION {
 #   ?institution wdt:P2013 ?Facebook
 # }
  
 # pour ajouter Instagram et Facebook décommenter les lignes 14 à 18 ; attention, cela peut excéder le temps défini par défaut d\'une requête (time out) et la requête peut échouer

  SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}')
spec(wikidata_df)
write.csv(wikidata_df, "wikidata_all.csv")
wikidata_df_masto <- wikidata_df %>% filter(!is.na(Mastodon))
wikidata_df_blue <- wikidata_df %>% filter( !is.na(Bluesky))
wikidata_df_link <- wikidata_df %>% filter(is.na(LinkedIn))
wikidata_df_threads <- wikidata_df %>% filter(!is.na(Threads))
count_mastodon <- length(wikidata_df_masto$Mastodon)
count_bluesky <- length(wikidata_df_blue$Bluesky)
count_linkedin <- length(wikidata_df_link$LinkedIn)
count_threads <- length(wikidata_df_threads$Threads)

count_networks <- c(count_mastodon, count_bluesky, count_linkedin, count_threads)
networks <- c("Mastodon", "Bluesky", "LinkedIn", "Threads")

df_networks <- data.frame(networks, count_networks)
```

```{r include=FALSE}

wikidata_df_libraries <- query_wikidata('SELECT DISTINCT ?institution ?institutionLabel ?Mastodon ?Bluesky ?LinkedIn ?Facebook ?Threads ?Instagram ?countryLabel WHERE {
  ?institution wdt:P31/wdt:P279* wd:Q7075;
    wdt:P17 ?country .

# Institutions de recherche : wd:Q31855
# bibliothèques : wd:Q7075

  {
    ?institution wdt:P4033 ?Mastodon
  } UNION {
    ?institution wdt:P12361 ?Bluesky
  } UNION {
    ?institution wdt:P4264 ?LinkedIn
  }  UNION {
    ?institution wdt:P11892 ?Threads
  } 
 #   UNION {
 #   ?institution wdt:P2003 ?Instagram
 # } UNION {
 #   ?institution wdt:P2013 ?Facebook
 # }
  
 # pour ajouter Instagram et Facebook décommenter les lignes 14 à 18 ; attention, cela peut excéder le temps défini par défaut d\'une requête (time out) et la requête peut échouer

  SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}')
write.csv(wikidata_df_libraries, "wikidata_libraries.csv")

wikidata_df_libraries_masto <- wikidata_df_libraries %>% filter(!is.na(Mastodon))
wikidata_df_libraries_blue <- wikidata_df_libraries %>% filter( !is.na(Bluesky))
wikidata_df_libraries_link <- wikidata_df_libraries %>% filter(is.na(LinkedIn))
wikidata_df_libraries_threads <- wikidata_df_libraries %>% filter(!is.na(Threads))
count_mastodon_libraries <- length(wikidata_df_libraries_masto$Mastodon)
count_bluesky_libraries <- length(wikidata_df_libraries_blue$Bluesky)
count_linkedin_libraries <- length(wikidata_df_libraries_link$LinkedIn)
count_threads_libraries <- length(wikidata_df_libraries_threads$Threads)

count_networks_libraries <- c(count_mastodon_libraries, count_bluesky_libraries, count_linkedin_libraries, count_threads_libraries)
networks_libraries <- c("Mastodon_libraries", "Bluesky_libraries", "LinkedIn_libraries", "Threads_libraries")

df_networks_libraries <- data.frame(networks_libraries, count_networks_libraries)





```

```{r réseaux, fig.show="hold", echo=FALSE, out.width="50%"}
library(ggplot2)
# Barplot basique
p <- ggplot(data=df_networks, aes(x=networks, y=count_networks)) +
  geom_bar(stat="identity", fill="#f45b56")
p + coord_flip() + labs(x="nombre de comptes ouverts",y="réseau",
               title="Institutions de recherche dans Wikidata")

p_libraries <- ggplot(data=df_networks_libraries, aes(x=networks_libraries, y=count_networks_libraries)) +
  geom_bar(stat="identity", fill="#15af29")
p_libraries + coord_flip() + labs(x="nombre de comptes ouverts",y="réseau",
               title="Bibliothèques dans Wikidata")

```
Selon les données prélevées au 24 janvier 2025, il semble que proportionnellement les bibliothèques aient été plus nombreuses que les institutions de recherche à investir Mastodon et un peu moins que ces dernières à investir Bluesky (même si nombre d'entre elles sont présentes sur les deux réseaux). L'investissement dans Threads est également un peu moins fort du côté des bibliothèques. Peut-être cela s'explique t-il par une sensibilité plus grande à l'égard de réseaux décentralisés ou transparents. Ce n'est qu'une hypothèse bien sûr qu'il faudra vérifier avec le temps ou bien avec des données plus représentatives que celles qui sont sur Wikidata.  

Dans quels pays trouve t-on le plus de comptes Mastodon rattachés à des institutions de recherche ?

```{r mastodon par pays institutions et bibliothèques, include=FALSE}
library(dplyr)
wikidata_df_langues <- wikidata_df %>% filter(!is.na(countryLabel))
mastodon_countries <- wikidata_df_langues$countryLabel
count_table <- table(mastodon_countries)
top10 <- sort(count_table, decreasing = TRUE)[1:10]
top10_df <- as.data.frame(top10)
colnames(top10_df) <- c("Pays", "Nombre")

wikidata_df_langues_libraries <- wikidata_df_libraries %>% filter(!is.na(countryLabel))
mastodon_countries_libraries <- wikidata_df_langues_libraries$countryLabel
count_table_libraries <- table(mastodon_countries_libraries)
top10_libraries <- sort(count_table_libraries, decreasing = TRUE)[1:10]
top10_df_libraries <- as.data.frame(top10_libraries)
colnames(top10_df_libraries) <- c("Pays_libraries", "Nombre_libraries")

```


```{r pays adopteurs de Mastodon, echo=FALSE, fig.show="hold", out.width="50%" }

library(ggplot2)
q <- ggplot(top10_df, aes(x = reorder(Pays, -Nombre), y = Nombre)) +
  geom_bar(stat = "identity", fill = "#f45b56") +
  labs(title = "Institutions de recherche sur Mastodon (10 premiers pays)", x = "Pays", y = "Nombre de comptes") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

q + coord_flip()

q_libraries <- ggplot(top10_df_libraries, aes(x = reorder(Pays_libraries, -Nombre_libraries), y = Nombre_libraries)) +
  geom_bar(stat = "identity", fill = "#15af29") +
  labs(title = "bibliothèque sur Mastodon (10 premiers pays)", x = "Pays", y = "Nombre de comptes") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

q_libraries + coord_flip()

```
Au 24 janvier 2025, l'Allemagne est le pays dont à la fois les institutions de recherche et les bibliothèques ont le plus investi Mastodon. Le nombre de comptes rattachés à l'Allemagne dans Wikidata est supérieur à celui des Etats-Unis. La principale différence entre institutions de recherche et bibliothèques concerne le placement des Pays-Bas. Tandis que ce pays n'occupe que la 9ème place dans le classement pour les Institutions de recherche, il obtient la troisième place (deuxième pour l'Europe devant la France) en ce qui concerne l'implantation de Mastodon dans les politiques de communication des bibliothèques. 

Il faudrait une recherche plus approfondie pour expliquer pourquoi Mastodon est mieux implanté dans les bibliothèques allemandes et néerlandaises que dans les bibliothèques françaises (et davantage utilisé par les institutions de recherche allemandes que par leurs équivalents français). L'histoire administrative de l'Allemagne et de la France (décentralisation vs centralisation) joue t-elle un rôle ? La nationalité du concepteur de l'application, Eugen Rochko joue t-elle un rôle dans ce niveau d'adoption ? Le public français, notamment scientifique, est-il plus simple à cette réputation de difficulté de Mastodon que nous contestons dans les faits ? La pression sociale pour aller d'une plateforme centralisée comme X à cette autre plateforme centralisée qu'est Bluesky est-elle plus grande ici que chez nos voisins d'Outre-Rhin ?
Il faut observer que le régime politique allemand est directement ciblé par la propagande politique du propriétaire de X [⁴], ce qui a conduit des collectivités locales à quitter plus rapidement X qu'en France. Les services du Délégué à la Protection des Données du Bad-Würtemberg [héberge une instance](https://bawü.social/explore) qui sert de référence aux administrations. 

En France, on reproche souvent à Mastodon d'encourager un "entre-soi", alors même que les algorithmes de X et de Meta poussent la bulle de filtre à des niveaux jamais atteints, qui permettent de se façonner un monde fidèle à l'image qu'on veut en avoir. Cette image défavorable tient sans doute au fait que le choix d'une instance implique un tiers de confiance, des affinités préalablement établies avant l'arrivée sur Mastodon. Par exemple, si on apprécie les travaux de la Quadrature du Net, on aura tendance à se faire héberger sur mamot.fr, l'instance mise en place par cette association. Pour autant, un internaute depuis son instance voit très majoritairement passer des messages provenant d'autres instances. 
Par ailleurs, beaucoup de personnes qui se retrouvent dans Mastodon avaient au préalable tenté leur chance sur Twitter et en sont partie dégoûtées, souvent bien avant le mouvement HelloquitteX. Les valeurs que ces personnes affichent sont de manière assez logique aux antipodes de celles de X. Plus les utilisateurs de X vantent les Tesla, les cryptomonnaies, l'énergie masculine chère à Marc Zuckerberg, et conspuent le wokisme et plus les valeurs écologiques dont le vélotaf, la régulation des flux financiers et les valeurs progressistes dont le féminisme et le respect des personnes LGBTQI+ s'affichent dans les statuts et les chartes de modération. 

Quant aux compétences techniques que les utilisateurices de Mastodon sont censées avoir en abondance, on devrait parler plus simplement d'une culture numérique, ou d'une forme de compréhension du numérique qui permet en effet de résister à la pression sociale qui fait transiter les utiliateurices d'une plateforme centralisée à une autre. 

## 2.3 Chiffres sur l'activité de notre compte

Ces chiffres seront mis à jour régulièrement en activant la procédure d'authentification qui rend possible l'activation du script sous-jacent à cette publication. 

- Le compte Mastodon SO_UnivRennes comporte <div class="blue">`r followers_number` followers</div>. 
- Nous sommes actuellement abonnés à <div class="blue">`r following_number` comptes</div>.  
- A travers ce compte, nous avons envoyé <div class="blue">`r status_number` statuts</div> (toots) constitués à la fois de <div class="blue">`r toots` messages que nous avons rédigés</div> et de <div class="blue">`r boosts` messages envoyés par d'autres que nous avons repostés</div> (boosts)
- Les toots de SO_UnivRennes ont été <div class="blue">`r favourites` fois mis en favoris</div> par des membres du réseau  
- Ils ont reçu <div class="blue">`r replies` réponses de la part d'internautes</div>. 
- de notre côté, nous avons envoyé <div class="blue">`r count_reply_to` messages de réponse</div> à des utilisateurs de Mastodon ou de Bluesky.
- ils ont été boostés <div class="blue">`r reblogs` fois</div>. 


## 2.4 qui sont nos followers

Par "Followers", on entend tous les détenteurs et détentrices de comptes qui peuvent nous suivre d'une autre instance de Mastodon, de la même instance, de Bluesky ou bien d'un autre service interopérable avec Mastodon via le protocole ActivityPub comme Peertube ou Pixelfeld. 

### 2.4.1 mots-clé liés aux followers

Les utilisateurs et utilisatrices de Mastodon mettent courarmment en avant des hashtags qui caractérisent leurs intérêts et facilitent ainsi leur signalement auprès de la communauté. Cette fonction s'appelle "features hashtags" et est disponible dans l'édition du profil.
Notre compte SO_UnivRennes arbore par exemple les hashtags suivants : 

<img src="images/hashtags.png" alt="liste des hashtags mis en évidence sur le profil du compte SO_UnivRennes" />

Voici la liste des hashtags arborés par nos followers :

```{r echo=FALSE}
library(dplyr)
library(stringr)
#pattern <- "\"https.*/tags/.*\""
pattern <- "(?<=/tags/)[^<\"]+"
# Apply the regex and extract the matched parts into a new column 'tag'
followers <- followers %>%
  mutate(tag = str_extract(followers$note, pattern))
followers$tag <- URLdecode(followers$tag)
tag_list <- followers$tag %>%
    .[!is.na(.) & . != "NA"]   # Extract the 'tag' column as a vector
#  unique()                 # Get unique tags

# Print the list of unique tags
cat(tag_list)
write.csv(tag_list,"tag_list.csv")
write.csv(followers,"followers.csv")
```


## 2.4.2 Instances des followers

```{r instance des followers, echo=FALSE}
# extracting instances from accounts can also be performed within rtoot : https://schochastics.github.io/rtoot2022/#/interlude-extract-instances-from-statuses-1
library(stringr)
followers_url <- (followers$url)
followers_url <- data.frame(followers_url, stringsAsFactors = FALSE)
followers_url <- followers_url %>%
  mutate(
    user_instance = str_split(followers_url, "://|@", simplify = TRUE)[, 2], # Second part (domain)
    user_alias = paste0("@", str_split(followers_url, "://|@", simplify = TRUE)[, 3]) # Third part (alias)
  )
instance <- unlist(followers_url$user_instance)
instance_count <- table(instance)
instance_count_dataframe <- as.data.frame(instance_count)
colnames(instance_count_dataframe) <- c("instance", "nombre")
instance_count_dataframe <- instance_count_dataframe %>%
  arrange(desc(nombre))
head_instance_count_dataframe <- head(instance_count_dataframe, n=12)
print(head_instance_count_dataframe)

bsky <- instance_count_dataframe$nombre[which(instance_count_dataframe$instance == "bsky.brid.gy/r/https")]

```

La provenance des followers est sans doute peu représentative de l'importance des instances dans les choix des communités scientifiques françaises. Ces instances sont d'ailleurs peu comparables entre elles, par leur taille et les communautés qu'elles visent à constituer. Social.numerique.gouv.fr n'est ouvert qu'à des institutions 100% publiques et ne comptait que 27 comptes actifs au 24 janvier 2025. Universite.social est destinée aux utilisateurices qui disposent d'un identifiant universitaire. Mastodon.social est ouvert à toutes et tous depuis 2017. Framapiaf, l'instance mise en place par l'association Framasoft a connu un vif succès à ces débuts mais a dédicé ensuiite de clore sa plateforme aux nouvelles inscriptions après avoir dépassé les 9000 abonnés. L'idée d'une croissance infinie est fort éloignée des préoccupations des administrateurs et administratrices de Mastodon qui doivent pouvoir équilibrer la taille d'une communauté avec le type de service et de modération qu'ils ou elles peuvent rendre. 
Parmi nos followers, l'instance social.sciences.re (940 comptes) est sur-représentée par rapport à celle de Piaille qui en compte 12000, Mais Piaille bien qu'administrée par des personnes gravitant dans le monde de la Science, comme Célian Godefroid, [juriste rattaché aux BU de Paris-Saclay](https://mastodon.social/@CelianGodefroid@piaille.fr) n'est pas une instance scientifique à proprement parler (contrairement à Fediscience et ses 1100 abonnés préoccupés de Recherche) 

Comme nous avons immédiatement activé un pont avec Bluesky, notre compte peut être suivi depuis ce réseau avec l'alias [SO-UnivRennes.mastodon.social.ap.brid.gy](https://bsky.app/profile/SO-UnivRennes.mastodon.social.ap.brid.gy), ce qui permet à <div class="blue">`r bsky`</div> utilisateurs ou utilisatrices de cette plateforme de rester en contact avec nous (à l'exception des messages privés que les ponts ne peuvent pas gérer. Les interactions publiques elles sont bien transmises) @turnerBridgyFedLinking2024. 


```{r traitement de la colonne content, include=FALSE}
# Load necessary libraries
library(rvest)
library(purrr)

# Assuming dataframe2 is your dataframe and 'content' is the column with HTML text
dataframe$content <- map_chr(dataframe$content, function(x) {
  tryCatch({
    # Read the HTML content as text and extract plain text
    read_html(x) %>% html_text()
  }, error = function(e) {
    # Return the original content if there is an error
    return(x)
  })
})

write_csv(dataframe, "SO_univrennes_toots_content.csv")# Now dataframe2$content will have the text without HTML tags
```


## 2.4.3 activité des followers

Nos actualités sont boostées par plusieurs de nos followers. Bien entendu l'écho qui en est fait, dépend du nombre de personnes qui suivent ces followers. Nous avons donc souhaité savoir qui étaient (en nombre de followers) nos abonné.e.s les plus influent.e.s. Voici la liste des 10 abonnés qui ont le plus grand score d'abonnés :

```{r audience des followers, include=FALSE}

library(rtoot)

# Account ID of the main account
id <- "112370075539544475"

# Fetch the followers list
followers_list <- get_account_followers(id)

# Check structure of followers_list
if (!is.null(followers_list) && "id" %in% names(followers_list)) {
  # Ensure display_name exists and has the correct length
  if (!"display_name" %in% names(followers_list)) {
    followers_list$display_name <- rep("", length(followers_list$id))
  }

  # Function to count followers for each user with error handling
  count_followers <- function(follower_id) {
    user_info <- tryCatch(
      get_account(follower_id), # Use get_account for specific user details
      error = function(e) {
        warning(paste("Error fetching data for user ID:", follower_id))
        return(NULL)
      }
    )
    if (!is.null(user_info) && "followers_count" %in% names(user_info)) {
      return(user_info$followers_count)
    } else {
      return(NA)
    }
  }

  # Iterate over followers and count their followers
  follower_counts <- sapply(followers_list$id, count_followers)

  # Ensure lengths match before creating data frame
  if (length(follower_counts) == length(followers_list$id)) {
    # Create a data frame to display follower counts
    result <- data.frame(
      follower_name = followers_list$display_name,
      follower_count = follower_counts,
      stringsAsFactors = FALSE
    )

    # View the results
    # result <- result[order(-result$follower_count),]
    #print(result)
    write.csv(result, "followers_count.csv")
  } else {
    stop("Mismatch in lengths between followers_list and follower_counts.")
  }
} else {
  stop("Failed to fetch followers list or unexpected structure.")
}


```


```{r ordonnancement activité followers, echo=FALSE}
result2 <-read.csv("followers_count.csv")
result2 <- result2[order(-result$follower_count),]
head_result2 <- head(result2, n=10)
print(head_result2)

```

## 2.5 Caractéristiques des toots envoyés par SO_UnivRennes

Dans cette partie, nous nous intéressons aux messages que envoyons sur Mastodon depuis notre compte SO_UnivRennes : sont-ils plutôt longs, courts ? La limite en nombre de caractères d'un message est fixée sur Mastodon par les propriétaires de chaque instance. 

### 2.5.1 longueur moyenne des toots

Le code emprunté pour générer ce graphique provient de la présentation des développeurs de Rtoot que nous avons déjà citée (@schochSoftwarePresentationRtoot2023a)

```{r distribution longueur toots, echo=FALSE}
library(tidyverse)
library(dplyr)
extract_application <- function(application) {
  if (length(application) == 0) { 
    return(NA) 
  } else { return(application$name) }
}
```


```{r eval=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
dataframe <- get_account_statuses(id, limit = 300L) 
tree <- dataframe %>% mutate(interface = map_chr(application, extract_application), length = nchar(content)) %>% filter(!is.na(interface)) %>% ggplot(aes(x = interface, y = length)) + geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 0.5)

png("images/tree.png")
dev.off()
```


![](images/tree.png)
L'instance qui héberge notre compte Mastodon.social a une limite de 500 caractères par message. Les toots de SO_UnivRennes ont en moyenne une longueur de **292 caractères**

```{r eval=FALSE, include=FALSE}
dataframe %>%
  mutate(
    interface = map_chr(application, extract_application),
    length = nchar(content)
  ) %>%
  filter(!is.na(interface)) %>%
  ggplot(aes(x = interface, y = length)) +
  geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 0.5)
```


```{r longueur moyenne toots, eval=FALSE, include=FALSE}
toot_length <- dataframe%>%summarise(mean(length(application)))
print(toot_length)
```


### 2.5.2 Liste des hashtags utilisés 

L'occurrence des hashtags que nous utilisons est significative du type de messages que nous postons. 
Rtoots récupère l'ensemble des toots (statuts) envoyés en format html. 
L'analyse de ce contenu passe donc par une phase de nettoyage où les balises html doivent être supprimées du contenu. Cela se fait au moyen des packages *rvest* et *purr*, [selon la méthode présentée par Stochastics](https://schochastics.github.io/rtoot2022/#/parsing-content-1) (@stochasticsInteractingMastodonAPI). 

```{r liste hashtags, echo=FALSE}
library(stringr)

# Extrait tous les hashtags de la colonne "content" du fichier statuts (SO_UNivRennes_toots.csv) au moyen d'une expression régulière
dataframe$hashtags <- str_extract_all(dataframe$content, "#\\w+")
# constitue une liste avec l'ensemble des hashtags présents dans ce tableau
hashtags <- unlist(dataframe$hashtags)

# compte la fréquence de tous ces hashtags
hashtag_count <- table(hashtags)

# convertit le résultat de l'opération antérieure sous la forme d'un dataframe
hashtag_count_dataframe <- as.data.frame(hashtag_count)

# renomme les colonnes du tableau
colnames(hashtag_count_dataframe) <- c("hashtag", "nombre")

# ordonne la liste des hashtage par ordre décroissant de fréquence
hashtag_count_dataframe <- hashtag_count_dataframe %>%
  arrange(desc(nombre))

# affiche le résultat de ce traitemeent
head_hashtag_count <- head(hashtag_count_dataframe, n=10)

print(head_hashtag_count)
```

### 2.5.3 langue utilisée pour les toots de SO_UnivRennes

Les développements de la science ouverte prennent parfois des chemins différents selon les pays ; il est important de pouvoir interagir avec des comptes d'autres pays, d'où l'envoi régulier de messages en anglais. 
le package R *textcat* permet d'identifier la langue des toots et d'obtenir des chiffres sur cet usage de l'anglais, qui reste, comme on le voit plus bas assez minoritaire en ce qui nous concerne :
```{r langue utilisée, include=FALSE}
library(textcat)

# le package textcat permet de distinguer les contenus selon la langue
dataframe$language <- textcat(dataframe$content)
print(dataframe$language)
# fait figurer les valeurs relatives à chaque langue dans un tableau
language_count <- table(dataframe$language)


# compte le nombre de textes en français et en anglais
language_count <- dataframe %>%
  filter(!is.na(language) & language != "") %>%
  group_by(language) %>%
  summarise(count = n(), .groups = "drop")

english_count <- language_count %>%
  filter(language == "english") %>%
  pull(count)

french_count <- language_count %>%
  filter(language == "french") %>%
  pull(count)


language_pie <- data.frame(
  language = c("English", "French"),
  count = c(english_count, french_count)
)
```

```{r graphique langues, echo=FALSE}
# Create the pie chart
ggplot(language_pie, aes(x = "", y = count, fill = language)) +
  geom_col(width = 1) + # Bar chart
  coord_polar(theta = "y") + # Convert to pie chart
  labs(title = "Language Distribution", x = NULL, y = NULL) +
  theme_void() + # Remove unnecessary chart elements
  theme(legend.title = element_blank())
```


### 2.5.4 Messages envoyés à des internautes

Bien entendu, notre compte sert à communiquer sur nos événements, ateliers, nouveautés concernant HAL et la politique Science Ouverte de notre établissement, ce qui est en soi déjà très important. Mais notre ambition est également de nourrir des interactions riches avec les utilisateurices du réseau : échanger des informations, des points de vue, discuter dans un climat serein, ce que X rendait impossible. 
Avec qui avons-nous engagé la conversation ?
Voici quelques personnes à qui nous avons répondu dernièrement sur le réseau :

```{r messages envoyés en réponse, echo=FALSE}
#library(rtoot)
#id <- "112370075539544475"
usernames <- sapply(reply_to, function(id) {
  account <- get_account(id)  # Fetch account details for each ID
  return(account$acct)        # Extract and return the username
})
handles_only <- usernames[grep("@", usernames)]
unique_handles <- unique(handles_only)
print(unique_handles)

```

Des échanges très riches dans la grande majorité des cas et qui installent des conversations dans le temps. Nous espérons pouvoir les prolonger sur des sujets divers avec les mêmes utilisateurices ou avec d'autres. 


# Références



---
[¹]: voir par exemple l'édito de Korben (https://korben.info/sacs-a-merde.html)
[²]: Collusion des Tech Bros, magnats de la technologie américaine pour soutenir une présidence qui sert leurs intérêts économiques et leur permet d'empêcher la constitution de lois anti-trust.
[³]: extrait de la charte de modération de Piaille : Il est interdit de publier ou diffuser intentionnellement des propos diffamatoires, calomnieux, ainsi que toute désinformation avec intention de tromper. Voir son application ici : https://piaille.fr/@CelianGodefroid/113865530173097447 
[⁴]: Elon Musk invite sur X les Allemands à voter pour l'AFD, un parti notoirement raciste et anti-démocratique adapte de la déportation des personnes issues de l'immigration vers des pays Africains.
